/* -------- server.js -------- */
import dotenv from 'dotenv';
import express from 'express';
import cors from 'cors';
import { OpenAI } from 'openai';
import path from 'path';
import { fileURLToPath } from 'url';

dotenv.config();
const app  = express();
const port = process.env.PORT || 8000;

/* ES-module-Ð´Ðµ __dirname Ð°Ð»Ñƒ */
const __filename = fileURLToPath(import.meta.url);
const __dirname  = path.dirname(__filename);

/* ---------- middlewares ---------- */
app.use(cors());
app.use(express.json());

/* Ð¤Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´ Ñ„Ð°Ð¹Ð»Ð´Ð°Ñ€Ñ‹ */
app.use(express.static(path.join(__dirname, '../frontend')));

/* SPA â†’ ÐºÐµÐ· ÐºÐµÐ»Ð³ÐµÐ½ Ð±Ð°ÑÒ›Ð° ÑÒ±Ñ€Ð°ÑƒÐ´Ñ‹ index.html-Ð³Ðµ Ð±Ð°Ò“Ñ‹Ñ‚Ñ‚Ð°Ñƒ */
app.get('*', (_, res) => {
  res.sendFile(path.join(__dirname, '../frontend/index.html'));
});

/* ---------- OpenAI ---------- */
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

/**
 * POST /api/generate
 * body: { topic: "History", num: 5 }
 * returns: [{ q, answers:[â€¦], correct }]
 */
app.post('/api/generate', async (req, res) => {
  const { topic = '', num = 5 } = req.body;

  try {
    const prompt = `
Generate ${num} multiple-choice quiz questions on "${topic}".
Return JSON array where each object has:
  q       â€“ question text
  answers â€“ array of 4 options
  correct â€“ index (0-3) of correct option
JSON only, no markdown.`;

    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages:[{ role: 'user', content: prompt }]
    });

    const data = JSON.parse(completion.choices[0].message.content);
    res.json(data);
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: 'OpenAI error' });
  }
});

/* ---------- start ---------- */
app.listen(port, () =>
  console.log(`ðŸš€  Server ready â†’ http://localhost:${port}`)
);